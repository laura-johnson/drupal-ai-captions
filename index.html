<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Myplanet reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/myplanet.css">
		<link rel="stylesheet" href="css/presentation.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<link rel="icon" href="lib/myplanet/logo/radiant-orange/mark-knockout.svg"/>

		<!-- Printing and PDF exports -->
		<script src="js/reveal-print.js"></script>
	</head>
	<body>
		<div class="reveal pattern--random">
			<div class="slides">
				<section class="intro" id="intro">
					<div class="logo-wrapper">
						<div class="logo"><span class="visually-hidden">Myplanet</span></div>
					</div>
				</section>
				<section class="title" id="title">
					<div class="grid-wrapper">
						<div class="header">
							<!-- Remove logo--full class to only show brand mark -->
							<div class="logo logo--full"><span class="visually-hidden">Myplanet</span></div>
						</div>
						<div class="content">
							<h1>I Think It’s a Kitten Wearing a Bowtie?</h1>
							<div class="description">
								Drupal Media Image Caption Suggestions Using AI
							</div>
						</div>
						<div class="credit">
							<hr/>
							<div class="label">Presented By</div>
							<div class="name">Laura Johnson</div>
							<div class="name">Boban Stanojevic</div>
							<div class="role">Senior Software Developers</div>
						</div>
						<aside class="notes">
								<ul>
										<li>Hi everyone and thanks for coming to our presentation on Image Caption Suggestions in Drupal using AI</li>
										<li>To start off, we'll do brief introductions. I'm Laura Johnson and this is Boban Stanojevic. We're both senior software developers at Myplanet</li>
										<li>Myplanet is a digital studio that specializes in smarter interfaces. We have a wide variety of clients and use a lot of different technologies including Drupal, AI implementations, custom JavaScript applications, mobile apps and more</li>
										<li>Myplanet is located in Toronto, Canada, which is where I live and Boban lives in Serbia.</li>
										<li>One really cool thing about this talk is that this is the first time Boban and I have met in person after working together for almost two years.</li>
										<li>So that is one of the really cool things about DrupalCon, is that it brings developers together from all over, including the ones you work with.</li>
										<li>Okay, on to the presentation! I'm going to talk about the where, the what and the why associated with this topic, and then Boban is going to do a live demo</li>
										<li>But first, the burning question: When you think about Image Caption Suggestions in Drupal using AI, one of the first questions you might ask yourself is, why? What's the use case for this?</li>
									</ul>
								</aside>
					</div>
				</section>
				<section id="blank">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section">Intro</div>
						</div>
						<div class="content">
							<h1>Why use AI image captions in a CMS?</h1>
							<ul>
								<li>To save time for authors and editors</li>
								<li>Offer caption suggestions</li>
								<li>For large archives of images</li>
								<li>A prompt for content authors to enter a proper caption</li>
								<li>As an educational tool that describes what types of captions are best for screen reader users</li>
							</ul>
							<aside class="notes">
								<p>There are all of the usual reasons for using image captions:</p>
							<ul>
								<li>Accessibility</li>
								<li>Compatibility with web standards</li>
								<li>To display text if an image doesn't load</li>
								<li>SEO</li>
								<li>So we've established that image captions are important. But often we don't have them. Why not?</li>
								<li>They're time consuming. As a developer, when I'm testing an image feature I almost only ever enter 'test' in the required alt field</li>
								<li>I would like to think that as a content author I would put more thought into it, but we know we all take shortcuts</li>
								<li>Large archives. If captioning one image seems time consuming, captioning an entire archive is often something that just won't get done</li>
								<li>Prompts. In the same way that a required field is a prompt to enter something, a caption generator button is a prompt to enter a full description rather than a single word or something nonsensical</li>
								<li>So, AI captioning does not mean that you don't have to worry about captioning anymore. You still have to pay attention and be an active participant. But it can be very helpful as an assistive tool.</li>
								<li>Now I'm going to get into some of the nitty gritty details about the AI model we're using, because we think it's super interesting and fun to play with, and we think you will as well.</li>
							</ul>
						</aside>
						</div>
					</div>
				</section>
				<section id="show-tell">
						<div class="grid-wrapper">
							<div class="header">
								<div class="logo"></div>
								<div class="section">Intro</div>
							</div>
							<div class="content">
									<h1>Background about the AI model</h1>
									<ul> 
											<li>API provided by IBM</li>
											<li>Based on a model called the <em>Show and Tell Model</em></li>
											<li>Developed by research scientists at Google</li>
											<li>Implemented with Tensorflow</li>
										</ul>
								<aside class="notes">
										<ul>
											<li>As Boban will explain a little later, it is very possible for any one of us to train our own model and to fine tune it ourselves using Tensorflow and other tools.</li>
											<li>For the purposes of this demo, we wanted to really concentrate on the integration of the API with Drupal, so we chose to use a pre-existing API and pre-trained model.</li>
											<li>So we used an API that is provided by IBM as part of a suite of AI tools that they have published. We have a link to it in the resources section of this slide deck, which we have published if you want to check it out</li>
											<li>Inspired by experiments that Google conducted into language translation using an encoder-decoder type of model</li>
											<li>In that version, the encoder was encoding a sentence</li>
											<li>A decoder generated the target sentence</li>
											</ul>
									</aside>
							</div>
						</section>
					<section id="deep-learning">
							<div class="grid-wrapper">
								<div class="header">
									<div class="logo"></div>
									<div class="section">Intro</div>
								</div>
								<div class="content">
									<h1>An <em>encoder-decoder</em> neural network.</h1>
									<p><strong>Encoder:</strong></p>
									<ul>
										<li>A deep convolutional neural network (DCNN) called Inception V3</li>
										<li>Pretrained using the ILSVRC-2012-CLS image classification dataset</li>
									</ul>
									<p><strong>Decoder:</strong></p>
									<ul><li>A RNN (Recurrent Neural Network)</li>
									<li>Also called along short-term memory (LSTM) network</li></ul>
								</div>
								<aside class="notes">
										<ul>
											<li>So they decided to try to make it work for image 'translation'</li>
											<li>They replaced the encoder RNN with a Deep Convolutional Neural Network</li>
											<li>The model 'encodes' the image into a vector, and 'decodes' it into a sentence.</li>
											<li>The Inception models are types of Convolutional Neural Networks designed by Google mainly for image classification and are currently considered to be state-of-the-art</li>
											<li>LSTM networks are commonly used for sequence modeling tasks such as language modeling</li>
											<li>When we say ‘deep’, or ‘deep learning’ in reference to a CNN or to any machine learning, it means that there are successive layers that data is passed through that transform the data before it is finally output.</li>
										</ul>
									</aside>
							</div>
						</section>
						<section id="cnn">
								<div class="grid-wrapper">
									<div class="header">
										<div class="logo"></div>
										<div class="section">Intro</div>
									</div>
									<div class="content">
											<h2>Deep convolutional neural network</h2>
											<ul>
													<li>The DCNN reduces the images into a form which is easier to process</li>
													<li>This image represents convolution in just one layer, but there may be several layers</li>
												</ul>
											<img src="lib/images/convolution2.gif">
									</div>
									<aside class="notes">
											<ul>
												<li>A Deep Convolutional Neural Network is an algorithm which can take in an input image and assign importance or weight to various aspects/objects in the image.</li>
												<li>The role of the DCNN is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction.</li>
												<li>In this image we see a filter, also called a ‘Kernel’, moving across an image.</li>
												<li>The first convolution layer is responsible for capturing the low-level features such as edges and color. With each successive layer, the kernel captures more high-level features as well.</li>
												<li>This architecture is inspired by the organization of the Visual Cortex in humans.</li>
											</ul>
										</aside>
								</div>
							</section>
				<section id="rnn">
						<div class="grid-wrapper">
							<div class="header">
								<div class="logo"></div>
								<div class="section">Intro</div>
							</div>
							<div class="content">
									<h2>Recurrent neural network</h2>
									<ul>
											<li>Captions are generated word-by-word</li>
											<li>Beam Search selects captions for the image, keeping only the top k candidates at each step</li>
											<li>They have found the best performance with a beam size of k = 3</li>
										</ul>
									<img src="lib/images/show_and_tell_architecture.png">
							</div>
							<aside class="notes">
									<ul>
										<li>Captions are generated word-by-word</li>
										<li>A number of captions are generated for a single image.</li>
										<li>The model uses beam search to select the most probable captions for the image.</li>
										<li>They keep only the top k candidates at each step, where the hyperparameter k is called the beam size.</li>
										<li>They have found the best performance with a beam size of k = 3, and you will see that this model returns three results to us.</li>
									</ul>
								</aside>
						</div>
					</section>
					<section id="dataset">
							<div class="grid-wrapper">
								<div class="header">
									<div class="logo"></div>
									<div class="section">Intro</div>
								</div>
								<div class="content">
										<h2>The Dataset</h2>
										<ul>
												<li>Different datasets will give you drastically different results</li>
												<li>The one that our model is trained on is fairly generic</li>
												<li>Microsoft Accessibility Initiative</li>
											</ul>
											<img src="lib/images/example_captions.jpg">
								</div>
								<aside class="notes">
										<ul>
												<li>Different datasets will give you drastically different results</li>
												<li>There are datasets that are publicly available. The one that our model is trained on is publicly available and fairly generic</li>
												<li>Some datasets are tailored to specific subjects, such as clothing recognition and classification</li>
												<li>Microsoft has a program called the Microsoft Ability Initiative which is dedicated to developing a dataset specifically designed to benefit vision impaired users</li>
												<li>It incorporates research on how end-users who are blind interpret the output of AI image labeling systems</li>
												<li>They are also researching how to incorporate more than just textual information - the alt attribute can potentially be multimedia, interactive, multi-dimensional</li>
												<li>This will be very useful both on its own and as information for anyone creating a dataset on what makes a caption most effective for visually impaired users.</li>
											</ul>
								</aside>
							</div>
						</section>
				<section id="accessibility">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section">Intro</div>
						</div>
						<div class="content">
								<h1>Why <em>not</em> use AI image captions?</h1>
								<ul>
									<li>AI captions are sometimes wrong <br>(very, very wrong)</li>
									<li>If incorrect, can be misleading for visually impaired users</li>
									<li>Captions should ideally convey the intent of the author</li>
								</ul>
								<img src="lib/images/captionbot.jpg">
						</div>
						<aside class="notes">
						<ul>
								<li>AI captions are sometimes wrong</li>
								<li>Microsoft published an online captioning API called CaptionBot and invited the internet to come and try it out</li>
								<li>The Internet uploaded a lot of interesting and often political images to see what it would say and got very funny results</li>
								<li>Google 'CaptionBot fails' for more examples</li>
							  <li>This, while funny, demonstrates one of the difficulties with AI, which is that captions should ideally convey the intent of the author</li>
								<li>If incorrect, can be misleading for visually impaired users</li>
								<li>From an SEO standpoint it is somewhat important that captions be accurate</li>
								<li>An improvement that will come at some point is that ML will be able to include the text surrounding an image and include that as input to construct more accurate captions. But we're not there yet.</li>
							</ul>
						</aside>
					</div>
				</section>
				<section id="blank">
						<div class="grid-wrapper">
							<div class="header">
								<div class="logo"></div>
								<div class="section">Intro</div>
							</div>
							<div class="content">
									<h1>Conclusion: use responsibly</h1>
									<ul>
										<li>Implement as an assistive tool rather than as the default</li>
										<li>Make it known to visually impaired users that there is a percentage of error</li>
										<li>Studies have shown that visually impaired users tend to trust the captions</li>
										<li>Prompt content authors to review the captions</li>
									</ul>
							</div>
						</div>
					</section>
				<section id="blank">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section">Live Demo</div>
						</div>
						<div class="content"><h1>It's time for the live demo!</h1></div>
					</div>
				</section>
				<section id="blank">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section">Code Walk-through</div>
						</div>
						<div class="content">https://github.com/myplanetdigital/drupal-ai-image-captions</div>
					</div>
				</section>
				<section id="blank">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section"></div>
						</div>
						<div class="content">
							<h1>Possible Improvements</h1>
							<ul>
									<li>Microsoft Accessibility Initiative</li>
									<li>More applications within Drupal</li>
								</ul>
						</div>
					</div>
				</section>
				<section id="blank">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section">References</div>
						</div>
						<div class="content"><h1>References</h1>
							<p><strong>Basis for IBM Image Captioning (TensorFlow):</strong> https://github.com/tensorflow/models/tree/master/research/im2txt</p>
							<p><strong>IBM MAX Image Caption Generator:</strong> https://github.com/IBM/MAX-Image-Caption-Generator/</p>
							<p><strong>IBM Max Image Caption Generator Homepage:</strong> https://developer.ibm.com/exchanges/models/all/max-image-caption-generator/</p>
							<p><strong>Link to the project:</strong> https://github.com/myplanetdigital/drupal-ai-image-captions</p>
							<p><strong>Microsoft Ability Initiative:</strong> </p>
								<ul>
										<li>https://www.microsoft.com/en-us/research/blog/microsoft-ability-initiative-a-collaborative-quest-to-innovate-in-image-captioning-for-people-who-are-blind-or-with-low-vision/</li>
										<li>https://www.microsoft.com/en-us/research/uploads/prod/2018/01/images_chi_two_appendices.pdf</li>
										<li>https://www.microsoft.com/en-us/research/uploads/prod/2016/10/captions_chi2017.pdf</li>
								</ul>
						</div>
					</div>
				</section>
				<!-- Team page can accommodate one or two profiles. -->
				<section class="team" id="team">
					<div class="grid-wrapper">
						<div class="header">
							<div class="logo"></div>
							<div class="section">Section</div>
						</div>
						<div class="content">
							<div class="profile">
								<div class="basics">
									<img src="lib/images/laura_profile_pic.jpg">
									<div class="name">Laura Johnson</div>
									<div class="role">Senior Software Developer</div>
									</div>
								<div class="details">
									<h2>Profile</h2>
									<p>Laura is a Senior Software Developer, Tech Lead, and Drupal Mentor at Myplanet. She has presented on diverse topics at DrupalCon and Accessibility conferences, and has written articles on the topic of Machine Learning and Web Accessibility. She holds Acquia Drupal 8 Developer and Front-end Developer Certifications. She is an organizer of Drupal North, the largest Drupal conference in Canada.</p>
								</div>
							</div>
							<div class="profile">
								<div class="basics">
									<img src="lib/images/portrait_boban.jpg">
									<div class="name">Boban Stanojevic</div>
									<div class="role">Senior Software Developer</div>
								</div>
								<div class="details">
									<h2>Profile</h2>
									<p>Boban is a Senior Software Developer at Myplanet. Knowledgable in various different platforms and tools, he is interested in making technology work for people.</p>
								</div>
							</div>
						</div>
					</div>
				</section>
				<section class="end color--radiant" id="end-radiant">
					<div class="logo-wrapper">
						<div class="logo"><span class="visually-hidden">Myplanet</span></div>
					</div>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>
		<script src="js/reveal-init.js"></script>
	</body>
</html>
